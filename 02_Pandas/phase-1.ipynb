{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bbd1967",
   "metadata": {},
   "source": [
    "## Pandas : Series and Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497ca28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc521dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series\n",
    "values = [10,20,30,40,50]\n",
    "s = pd.Series(values)\n",
    "print(\"Series:\\n\", s)\n",
    "\n",
    "s1 = pd.Series(values, index=['a','b','c','d','a'])\n",
    "print(\"Series with custom index:\\n\", s1)\n",
    "print(\"Values at index:\\n\", s1.loc['a'])\n",
    "\n",
    "# Data Frame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Mike', 'Bob', 'Alice'],\n",
    "    'age': [44, 39, 29],\n",
    "    'job': ['Architect', 'Engineer', 'Developer']\n",
    "})\n",
    "print(\"Data Frames:\\n\", df)\n",
    "\n",
    "df1 = df.set_index('name')\n",
    "print(\"Data Frames with custom index:\\n\", df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74111050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'a': [1,2,3]\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'a': [4,5,6]\n",
    "})\n",
    "print(\"adding data frames:\\n\", df2 + df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cada17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Export Data\n",
    "\n",
    "# reset index to default\n",
    "df1 = df1.reset_index()\n",
    "\n",
    "# store data in csv file\n",
    "df1.to_csv('mydata.csv')\n",
    "\n",
    "# read csv file data\n",
    "pd.read_csv('mydata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf34eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to json data\n",
    "df1.to_json('mydata.json')\n",
    "\n",
    "df1.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee9731",
   "metadata": {},
   "source": [
    "### Data Exploration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd831877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = fetch_california_housing(as_frame=True).frame\n",
    "\n",
    "# pd.options.display.max_columns = 5\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba501dd",
   "metadata": {},
   "source": [
    "### Statistical Functions & Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a964aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.describe()\n",
    "\n",
    "data_frame.HouseAge\n",
    "type(data_frame.HouseAge)\n",
    "\n",
    "data_frame['HouseAge'].sum()\n",
    "\n",
    "data_frame['HouseAge'].hist()\n",
    "\n",
    "data_frame.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df677029",
   "metadata": {},
   "source": [
    "### Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ae46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Mike', 'Bob', 'Alice'],\n",
    "    'age': [44, 39, 29],\n",
    "    'job': ['Architect', 'Engineer', 'Developer']\n",
    "})\n",
    "\n",
    "# df.loc[1]\n",
    "\n",
    "df = df.set_index('name')\n",
    "df.loc['Alice']\n",
    "\n",
    "df.iloc[1]\n",
    "df.loc['Alice', 'age']\n",
    "df.iloc[1,0]\n",
    "\n",
    "df.at['Alice', 'age']\n",
    "df.iat[1,0]\n",
    "\n",
    "df.loc['John'] = [54, 'Professor']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa8dc8",
   "metadata": {},
   "source": [
    "### Manipulating Data (Applying Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.age = df.age * 2\n",
    "# df\n",
    "\n",
    "def myfunction(x):\n",
    "    if x%3 == 0:\n",
    "        return x ** 2\n",
    "    else:\n",
    "        return x // 2\n",
    "    \n",
    "df.age.apply(myfunction)\n",
    "\n",
    "def myfun(x):\n",
    "    if x.endswith('r'):\n",
    "        return 'Without Job'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df.job.apply(myfun)\n",
    "\n",
    "df.age.apply(lambda x: x*3 if x % 4 == 0 else x // 2)\n",
    "\n",
    "df['summary'] = df.apply(lambda row: f'Age: {row[\"age\"]}, Job: {row[\"job\"]}', axis=1)\n",
    "df\n",
    "\n",
    "df = df.drop('summary', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a7969",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b402073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at['Alice', 'age'] = float('nan')\n",
    "df.info()\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "df.fillna(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f313d",
   "metadata": {},
   "source": [
    "### Iterating Over Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8deded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Mike', 'Bob', 'Alice'],\n",
    "    'age': [44, 39, 29],\n",
    "    'job': ['Architect', 'Engineer', 'Developer']\n",
    "})\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(row['job'])\n",
    "\n",
    "for i, col in df.items():\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b203169",
   "metadata": {},
   "source": [
    "### Filtering & Querying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080811d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Mike', 'Bob', 'Alice'],\n",
    "    'age': [44, 39, 29],\n",
    "    'job': ['Architect', 'Engineer', 'Developer']\n",
    "})\n",
    "\n",
    "df.age > 40 \n",
    "df[df.age > 40]\n",
    "\n",
    "df[(df.age > 40) & (df.job.notna())]\n",
    "\n",
    "df[(df.name.str.endswith('e')) & (df.age.notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d00f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "df['birthday'] = df['age'].apply(lambda x: dt.datetime.now() - dt.timedelta(days=365*x))\n",
    "\n",
    "df[df.birthday.dt.year > 1985]\n",
    "\n",
    "df.query('age > 30')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77fc44",
   "metadata": {},
   "source": [
    "### Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Mike', 'Bob', 'Alice'],\n",
    "    'age': [44, 39, 29],\n",
    "    'job': ['Architect', 'Engineer', 'Developer']\n",
    "})\n",
    "\n",
    "df.groupby('job').aggregate({\n",
    "    'age': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302e262",
   "metadata": {},
   "source": [
    "### Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('age')\n",
    "\n",
    "df.sort_values('age', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9545023",
   "metadata": {},
   "source": [
    "### Merging, Concatenating & Joining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59847e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'Item': ['A', 'B', 'C'],\n",
    "    'Price': [10,20,30],\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'Item': ['D', 'E', 'F'],\n",
    "    'Price': [40,50,60]\n",
    "})\n",
    "\n",
    "pd.concat([df1,df2]).reset_index().drop('index', axis=1)\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'Item': ['A', 'B', 'C'],\n",
    "    'Price': [10,20,30],\n",
    "})\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'Item': ['X', 'Y', 'Z'],\n",
    "    'Price': [True, True, False],\n",
    "})\n",
    "\n",
    "pd.concat([df3,df4], axis=1)\n",
    "pd.merge(df1, df4, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b24e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({\n",
    "    'Price': [10,20,30],\n",
    "}, index=['A', 'B', 'C'])\n",
    "\n",
    "df6 = pd.DataFrame({\n",
    "    'Country': ['X','Y','Z'],\n",
    "}, index=['A', 'B', 'C'])\n",
    "\n",
    "df5.join(df6)\n",
    "df5.join(df6, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d177a",
   "metadata": {},
   "source": [
    "**Pandas** is a powerful **data analysis and manipulation library** in Python. It provides easy-to-use **data structures** and functions to work with **structured data**, especially **tabular data** (like Excel spreadsheets or SQL tables).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Key Features:\n",
    "\n",
    "* **`DataFrame`**: 2D table-like data structure (rows and columns).\n",
    "* **`Series`**: 1D labeled array (like a single column).\n",
    "* **Data cleaning**: Handle missing data, filter, sort, group, merge, etc.\n",
    "* **Data loading**: Read/write from CSV, Excel, SQL, JSON, and more.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob'], 'Age': [25, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "    Name  Age\n",
    "0  Alice   25\n",
    "1    Bob   30\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Why Use Pandas?\n",
    "\n",
    "* Makes **data analysis** faster and easier.\n",
    "* Widely used in **data science**, **machine learning**, and **finance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5592131",
   "metadata": {},
   "source": [
    "### Series and DataFrames\n",
    "---\n",
    "\n",
    "### ✅ **1. Series**\n",
    "\n",
    "* A **Series** is like a **single column** in a DataFrame.\n",
    "* Internally, it’s a **1D labeled array** (similar to a dictionary).\n",
    "* Created from a list, with default index `0, 1, 2...` or custom index.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
    "```\n",
    "\n",
    "* Index can have **duplicate values**.\n",
    "* You can access elements using `.loc[index]`.\n",
    "\n",
    "```python\n",
    "s.loc['a']  # Returns value(s) for index 'a'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. DataFrame**\n",
    "\n",
    "* A **DataFrame** is a **2D labeled table** (like an Excel sheet or SQL table).\n",
    "* Think of it as a **collection of Series** (columns).\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"Mike\", \"Bob\", \"Alice\"],\n",
    "    \"age\": [30, 80, 45],\n",
    "    \"job\": [\"Programmer\", \"Clerk\", \"Designer\"]\n",
    "})\n",
    "```\n",
    "\n",
    "* Has default row indices: `0, 1, 2...`\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. Setting the Index**\n",
    "\n",
    "* You can **change the index** to a specific column:\n",
    "\n",
    "```python\n",
    "df = df.set_index(\"name\")  # Sets \"name\" column as index\n",
    "```\n",
    "\n",
    "* Always **assign back** to `df` (i.e. `df = df.set_index(...)`)\n",
    "\n",
    "  > Otherwise, the change is not saved.\n",
    "\n",
    "* ⚠️ Avoid using `inplace=True` — it works but is **bad practice**.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Indexing with `.loc`**\n",
    "\n",
    "* Use `.loc[index_label]` to access rows by index label:\n",
    "\n",
    "```python\n",
    "df.loc[\"Mike\"]  # Accesses the row where name == \"Mike\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Index Alignment in Operations**\n",
    "\n",
    "* When performing **arithmetic operations** on DataFrames, Pandas aligns **by index**, not by position.\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame({\"A\": [1, 2, 3]}, index=[0, 1, 2])\n",
    "df2 = pd.DataFrame({\"A\": [10, 20, 30]}, index=[1, 2, 0])\n",
    "\n",
    "result = df1 + df2\n",
    "```\n",
    "\n",
    "* Result aligns rows by index values:\n",
    "\n",
    "```\n",
    "   A\n",
    "0  31   # 1 + 30\n",
    "1  22   # 2 + 20\n",
    "2  13   # 3 + 10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. DataFrame Operations Summary**\n",
    "\n",
    "You can do many operations with DataFrames:\n",
    "\n",
    "* `filter`, `query`, `iterate`, `sort`, `group`, `merge`, `concatenate`, `join`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Summary Pointers:\n",
    "\n",
    "| Concept           | Description                                                  |\n",
    "| ----------------- | ------------------------------------------------------------ |\n",
    "| `Series`          | 1D labeled array (like a dict); single column in DataFrame   |\n",
    "| `DataFrame`       | 2D labeled data structure; collection of Series              |\n",
    "| `Index`           | Labels for rows (default: 0,1,2,...); can be customized      |\n",
    "| `.loc[]`          | Access rows by index label                                   |\n",
    "| `set_index()`     | Set a specific column as index (reassign to make persistent) |\n",
    "| `Index Alignment` | Arithmetic operations align on index, not on row order       |\n",
    "| `Avoid inplace`   | Prefer assigning result to a variable over `inplace=True`    |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01986d1",
   "metadata": {},
   "source": [
    "### Import & Export Data : **Pandas Export & Import Concepts Summary** (12:39)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Resetting the Index**\n",
    "\n",
    "* Before exporting, you often want to **reset the index** so it becomes a regular column (instead of being used as a row label).\n",
    "\n",
    "```python\n",
    "df = df.reset_index()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Exporting a DataFrame**\n",
    "\n",
    "You can export a DataFrame to many formats using `.to_<format>()`.\n",
    "\n",
    "#### Common Export Formats and Methods:\n",
    "\n",
    "| Format  | Method                          | Notes                                |\n",
    "| ------- | ------------------------------- | ------------------------------------ |\n",
    "| CSV     | `df.to_csv(\"filename.csv\")`     | Most commonly used                   |\n",
    "| JSON    | `df.to_json(\"filename.json\")`   | Exports as a dictionary-like JSON    |\n",
    "| Excel   | `df.to_excel(\"filename.xlsx\")`  | Requires `openpyxl` or `xlsxwriter`  |\n",
    "| HTML    | `df.to_html(\"filename.html\")`   | Renders as `<table>` in HTML         |\n",
    "| Dict    | `df.to_dict()`                  | Converts to a Python dictionary      |\n",
    "| Parquet | `df.to_parquet(\"file.parquet\")` | Good for large, binary tabular data  |\n",
    "| Pickle  | `df.to_pickle(\"file.pkl\")`      | Serializes DataFrame (Python-native) |\n",
    "| SQL     | `df.to_sql(...)`                | Used with databases                  |\n",
    "| XML     | `df.to_xml(\"filename.xml\")`     | Exports as XML                       |\n",
    "\n",
    "#### 👉 **Avoid Unwanted Index in Export**\n",
    "\n",
    "Use `index=False` to prevent exporting the index as a column:\n",
    "\n",
    "```python\n",
    "df.to_csv(\"filename.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. Viewing Exported CSV in Terminal**\n",
    "\n",
    "* You can verify the export by running:\n",
    "\n",
    "```bash\n",
    "cat filename.csv\n",
    "```\n",
    "\n",
    "* Without `index=False`, you’ll see an unnamed column added for the index.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Importing a DataFrame**\n",
    "\n",
    "Use `pd.read_<format>()` to import.\n",
    "\n",
    "#### Common Import Methods:\n",
    "\n",
    "| Format  | Method                            | Notes                                  |\n",
    "| ------- | --------------------------------- | -------------------------------------- |\n",
    "| CSV     | `pd.read_csv(\"filename.csv\")`     | Default index may show as “Unnamed: 0” |\n",
    "| JSON    | `pd.read_json(\"filename.json\")`   | Can load structured records            |\n",
    "| Excel   | `pd.read_excel(\"filename.xlsx\")`  | Can read specific sheets               |\n",
    "| HTML    | `pd.read_html(\"filename.html\")`   | Returns list of tables                 |\n",
    "| Parquet | `pd.read_parquet(\"file.parquet\")` | Fast and efficient                     |\n",
    "| Pickle  | `pd.read_pickle(\"file.pkl\")`      | Use only with trusted sources          |\n",
    "| SQL     | `pd.read_sql(...)`                | Read from SQL databases                |\n",
    "| XML     | `pd.read_xml(\"filename.xml\")`     | Parses XML structure                   |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Handling Index Column on Import**\n",
    "\n",
    "* If the index column was unintentionally exported:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"filename.csv\", index_col=0)  # Treat first column as index\n",
    "```\n",
    "\n",
    "* If index was **not** exported:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"filename.csv\")  # No need for index_col\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. JSON Export Format**\n",
    "\n",
    "* Index is used as the **key** in exported JSON.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"0\": {\"name\": \"Mike\", \"age\": 30, \"job\": \"Programmer\"},\n",
    "  \"1\": {\"name\": \"Bob\", \"age\": 80, \"job\": \"Clerk\"},\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **7. `.to_dict()`**\n",
    "\n",
    "* Converts DataFrame to a native Python dictionary.\n",
    "\n",
    "```python\n",
    "df.to_dict()\n",
    "```\n",
    "\n",
    "* Often resembles the JSON structure but is a Python object.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **8. HTML Export**\n",
    "\n",
    "* Converts DataFrame into a valid HTML table.\n",
    "\n",
    "```python\n",
    "df.to_html(\"filename.html\")\n",
    "```\n",
    "\n",
    "* Useful for embedding in web pages.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Final Tips\n",
    "\n",
    "| Tip                                                                                                   | Description |\n",
    "| ----------------------------------------------------------------------------------------------------- | ----------- |\n",
    "| Use `index=False` when exporting if you don’t want the index in the file.                             |             |\n",
    "| Always **inspect your export** (e.g. using `cat` or opening in Excel) to ensure structure is correct. |             |\n",
    "| Choose **format based on your use-case**:                                                             |             |\n",
    "\n",
    "* CSV for simple tabular data\n",
    "* JSON for structured data\n",
    "* Pickle/Parquet for speed\n",
    "* HTML/XML for web/data exchange |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff59218",
   "metadata": {},
   "source": [
    "### 📊 **Pandas: Exploring Real Datasets** : Data Exploration Functions (17:00)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Loading a Dataset**\n",
    "\n",
    "* Use built-in datasets from external libraries like **`scikit-learn`**.\n",
    "* Install with:\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn matplotlib\n",
    "```\n",
    "\n",
    "* Example: Load the **California Housing** dataset as a DataFrame:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame  # Extract the actual DataFrame\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Inspecting the DataFrame**\n",
    "\n",
    "#### 🔹 View First Rows\n",
    "\n",
    "```python\n",
    "df.head()       # First 5 rows\n",
    "df.head(10)     # First 10 rows\n",
    "```\n",
    "\n",
    "#### 🔹 View Last Rows\n",
    "\n",
    "```python\n",
    "df.tail()       # Last 5 rows\n",
    "df.tail(10)     # Last 10 rows\n",
    "```\n",
    "\n",
    "#### 🔹 View Random Rows\n",
    "\n",
    "```python\n",
    "df.sample()     # One random row\n",
    "df.sample(10)   # 10 random rows\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. Columns Overview**\n",
    "\n",
    "#### 🔹 View Column Names\n",
    "\n",
    "```python\n",
    "df.columns             # Returns Index object\n",
    "list(df.columns)       # Converts to list (useful for large datasets)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Control Display Settings**\n",
    "\n",
    "When there are **too many columns**, Pandas may hide some with `...`\n",
    "\n",
    "#### 🔹 Limit visible columns:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 5  # Limits display to 5 columns\n",
    "```\n",
    "\n",
    "#### 🔹 Show more columns (or all):\n",
    "\n",
    "```python\n",
    "pd.options.display.max_columns = 100  # Show up to 100 columns\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. DataFrame Summary Info**\n",
    "\n",
    "Use `.info()` to get **structure-level metadata** about the DataFrame:\n",
    "\n",
    "```python\n",
    "df.info()\n",
    "```\n",
    "\n",
    "#### It shows:\n",
    "\n",
    "* Total entries (rows)\n",
    "* Column names and data types\n",
    "* Count of **non-null** (non-missing) values\n",
    "* Memory usage\n",
    "\n",
    "#### 🔸 Example output:\n",
    "\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 20640 entries, 0 to 20639\n",
    "Data columns (total 9 columns):\n",
    "  #   Column         Non-Null Count  Dtype\n",
    " ---  ------         --------------  -----\n",
    "  0   MedInc         20640 non-null  float64\n",
    "  ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. Data Types in Pandas**\n",
    "\n",
    "* **float64, int64, object** (general-purpose type for mixed values like strings).\n",
    "* You can mix types, but **performance is best** when column types are consistent (e.g., all numeric).\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **7. Handling Missing Data (Preview)**\n",
    "\n",
    "* Use `.info()` to identify missing values (non-null < total rows).\n",
    "* You may:\n",
    "\n",
    "  * Drop columns/rows with missing values\n",
    "  * Fill them with default values\n",
    "\n",
    "> These are common preprocessing steps in data cleaning and ML workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Key Takeaways\n",
    "\n",
    "| Concept                          | Description                                         |\n",
    "| -------------------------------- | --------------------------------------------------- |\n",
    "| `head()`, `tail()`, `sample()`   | Quickly preview different parts of the dataset      |\n",
    "| `df.columns`                     | View column names                                   |\n",
    "| `pd.options.display.max_columns` | Control how many columns Pandas displays            |\n",
    "| `df.info()`                      | Get summary: shape, missing values, types           |\n",
    "| Data types                       | Keep types consistent for performance               |\n",
    "| Real dataset loading             | Use `sklearn.datasets.fetch_*` for real-world demos |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b998a",
   "metadata": {},
   "source": [
    "### 📈 **Pandas: Statistical Analysis & Visualization** : Statistical Functions & Plotting (22:24)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Summary Statistics with `describe()`**\n",
    "\n",
    "* Quickly get an overview of the dataset’s numeric columns:\n",
    "\n",
    "```python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "* `count`: non-null entries\n",
    "* `mean`: average value\n",
    "* `std`: standard deviation\n",
    "* `min`, `25%`, `50% (median)`, `75%`, `max`: percentiles\n",
    "\n",
    "> Helpful for understanding **data distribution**, **outliers**, and **spread**.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Accessing Columns**\n",
    "\n",
    "Two ways to access a column (returns a **Pandas Series**):\n",
    "\n",
    "```python\n",
    "df.HouseAge\n",
    "df[\"HouseAge\"]\n",
    "```\n",
    "\n",
    "Check type:\n",
    "\n",
    "```python\n",
    "type(df[\"HouseAge\"])  # pandas.core.series.Series\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. Common Statistical Methods on Series**\n",
    "\n",
    "| Function          | Description               |\n",
    "| ----------------- | ------------------------- |\n",
    "| `mean()`          | Average value             |\n",
    "| `median()`        | Middle value              |\n",
    "| `mode()`          | Most frequent value       |\n",
    "| `min()` / `max()` | Smallest / largest value  |\n",
    "| `std()`           | Standard deviation        |\n",
    "| `count()`         | Number of non-null values |\n",
    "| `sum()`           | Sum of all values         |\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "df[\"HouseAge\"].mean()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Visualizing Distributions: Histograms**\n",
    "\n",
    "Basic histogram:\n",
    "\n",
    "```python\n",
    "df[\"HouseAge\"].hist()\n",
    "```\n",
    "\n",
    "#### 🔹 Customizing with Matplotlib\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"HouseAge\"].hist()\n",
    "plt.title(\"House Age\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 🔹 Set figure size:\n",
    "\n",
    "```python\n",
    "df[\"HouseAge\"].hist(figsize=(12, 8))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Other Plot Types**\n",
    "\n",
    "* Use `.plot()` with different types:\n",
    "\n",
    "```python\n",
    "df[\"HouseAge\"].plot(kind=\"line\")  # Line plot\n",
    "df[\"HouseAge\"].plot(kind=\"bar\")   # Bar chart\n",
    "df[\"HouseAge\"].plot(kind=\"pie\")   # Pie chart\n",
    "```\n",
    "\n",
    "> Note: Pie and bar may not make much sense for continuous/numeric data.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. Visualize All Columns**\n",
    "\n",
    "#### 🔹 Histograms for all features:\n",
    "\n",
    "```python\n",
    "df.hist(figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "```\n",
    "\n",
    "#### 🔹 Line plot for all features (works well for time series):\n",
    "\n",
    "```python\n",
    "df.plot()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **7. Visualizing Stock Data Example with Yahoo Finance**\n",
    "\n",
    "#### Install and import `yfinance`:\n",
    "\n",
    "```bash\n",
    "pip install yfinance\n",
    "```\n",
    "\n",
    "```python\n",
    "import yfinance as yf\n",
    "```\n",
    "\n",
    "#### Fetch Apple stock data:\n",
    "\n",
    "```python\n",
    "stock_df = yf.download(\"AAPL\")\n",
    "```\n",
    "\n",
    "**Stock data includes:**\n",
    "\n",
    "* `Open`, `High`, `Low`, `Close`, `Adj Close`, `Volume`\n",
    "\n",
    "#### Plot a specific column:\n",
    "\n",
    "```python\n",
    "stock_df[\"Close\"].plot()\n",
    "```\n",
    "\n",
    "#### Plot entire DataFrame:\n",
    "\n",
    "```python\n",
    "stock_df.plot()\n",
    "```\n",
    "\n",
    "> You can later **select or exclude** specific columns to refine visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Key Takeaways**\n",
    "\n",
    "| Feature                               | Description                                                  |\n",
    "| ------------------------------------- | ------------------------------------------------------------ |\n",
    "| `df.describe()`                       | One-line statistical overview of all numeric columns         |\n",
    "| `Series.mean(), std(), median()` etc. | Apply directly on columns                                    |\n",
    "| `df.hist()`                           | Histogram for entire DataFrame                               |\n",
    "| `Series.hist()`                       | Histogram for one column                                     |\n",
    "| `df.plot()` + `kind=`                 | Line, bar, pie, histogram, etc.                              |\n",
    "| `matplotlib.pyplot`                   | For customizing plots (title, size, layout)                  |\n",
    "| `yfinance` + `.download()`            | Stock data as Pandas DataFrame for time series visualization |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17520c32",
   "metadata": {},
   "source": [
    "### 🧩 **Pandas: Selecting & Manipulating DataFrame Values** : Accessing Data (29:20)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Creating the DataFrame**\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"Mike\", \"Alice\", \"Bob\"],\n",
    "    \"age\": [30, 45, 80],\n",
    "    \"job\": [\"programmer\", \"accountant\", \"clerk\"]\n",
    "})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Selecting Columns (Subset of Columns)**\n",
    "\n",
    "Select single or multiple columns:\n",
    "\n",
    "```python\n",
    "df[\"age\"]                   # Single column (Series)\n",
    "df[[\"name\", \"job\"]]         # Multiple columns (DataFrame)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. Selecting Rows by Index**\n",
    "\n",
    "Use `loc` (label-based) or `iloc` (position-based):\n",
    "\n",
    "```python\n",
    "df.loc[1]       # Row at index label 1\n",
    "df.iloc[1]      # Row at position 1\n",
    "```\n",
    "\n",
    "Set index to a column:\n",
    "\n",
    "```python\n",
    "df = df.set_index(\"name\")\n",
    "df.loc[\"Alice\"]             # Now 'name' is the index\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Selecting Specific Values (Cells)**\n",
    "\n",
    "#### 🔹 With `loc` and `iloc`:\n",
    "\n",
    "```python\n",
    "df.loc[\"Alice\", \"age\"]      # 45\n",
    "df.iloc[1, 0]               # 45 (second row, first column)\n",
    "```\n",
    "\n",
    "#### 🔹 Optimized for scalar access: `at` and `iat`\n",
    "\n",
    "* Faster for single values:\n",
    "\n",
    "```python\n",
    "df.at[\"Alice\", \"age\"]       # 45\n",
    "df.iat[1, 0]                # 45\n",
    "```\n",
    "\n",
    "> ❗ `at` / `iat` **cannot return full rows/columns**—only individual values.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Modifying Values**\n",
    "\n",
    "#### 🔹 Update a single cell:\n",
    "\n",
    "```python\n",
    "df.at[\"Alice\", \"age\"] = 60\n",
    "```\n",
    "\n",
    "#### 🔹 Update a whole row:\n",
    "\n",
    "```python\n",
    "df.loc[\"Alice\"] = [75, \"clerk\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. Adding New Rows**\n",
    "\n",
    "You can directly assign a new index using `loc`:\n",
    "\n",
    "```python\n",
    "df.loc[\"John\"] = [90, \"teacher\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **7. Slicing Data**\n",
    "\n",
    "#### 🔹 Row slicing with `iloc` (end is exclusive):\n",
    "\n",
    "```python\n",
    "df.iloc[0:2]                # Rows 0 and 1\n",
    "df.iloc[0:3, 1]             # Column 1 from rows 0 to 2\n",
    "df.iloc[:, 1]               # All rows, column 1\n",
    "df.iloc[:, :]               # Everything (entire DataFrame)\n",
    "```\n",
    "\n",
    "> ✅ Works on **rows**, **columns**, or both:\n",
    "\n",
    "```python\n",
    "df.iloc[0:3, 0:2]           # First 3 rows, first 2 columns\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Key Takeaways**\n",
    "\n",
    "| Feature                 | Function                            | Description               |\n",
    "| ----------------------- | ----------------------------------- | ------------------------- |\n",
    "| Select rows by label    | `df.loc[]`                          | Index-based (e.g. `name`) |\n",
    "| Select rows by position | `df.iloc[]`                         | Integer-based             |\n",
    "| Select cell (faster)    | `df.at[]` / `df.iat[]`              | Optimized scalar access   |\n",
    "| Slice rows/columns      | `iloc[start:stop]`                  | Rows/columns by range     |\n",
    "| Update cell             | `df.at[row, col] = value`           | Modify specific value     |\n",
    "| Add row                 | `df.loc[new_index] = [values]`      | Appends new data          |\n",
    "| Select columns          | `df[\"col\"]`, `df[[\"col1\", \"col2\"]]` | Subset of columns         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5296e6",
   "metadata": {},
   "source": [
    "\n",
    "### 🧠 **Pandas: Applying Functions & Transforming Columns and Rows** : Manipulating Data (Applying Functions) (35:29)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Column-wise Arithmetic Operations**\n",
    "\n",
    "Basic transformations on a single column:\n",
    "\n",
    "```python\n",
    "df[\"age\"] * 2              # Multiply values by 2\n",
    "df[\"age\"] ** 2             # Square values\n",
    "df[\"age\"] = df[\"age\"] / 2  # Store result back (returns floats)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Conditional Logic with Custom Functions**\n",
    "\n",
    "Apply conditional logic to a column using a **custom function**:\n",
    "\n",
    "```python\n",
    "def transform_age(x):\n",
    "    if x % 3 == 0:\n",
    "        return x ** 2\n",
    "    else:\n",
    "        return x // 2\n",
    "\n",
    "df[\"age\"] = df[\"age\"].apply(transform_age)\n",
    "```\n",
    "\n",
    "* **`.apply()`** is used to apply a function **element-wise** to a column.\n",
    "* Conditions inside the function allow complex logic (e.g., squaring if divisible by 3, floor-divide otherwise).\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. String-Based Conditional Transformation**\n",
    "\n",
    "Example: Modify job titles based on string conditions.\n",
    "\n",
    "```python\n",
    "def clean_job(x):\n",
    "    if x.endswith(\"r\"):\n",
    "        return \"without job\"\n",
    "    return x\n",
    "\n",
    "df[\"job\"] = df[\"job\"].apply(clean_job)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Using Lambda Functions for Simpler Logic**\n",
    "\n",
    "Quick one-liners for simple logic:\n",
    "\n",
    "```python\n",
    "df[\"age\"] = df[\"age\"].apply(lambda x: x ** 2 if x % 10 == 0 else x / 2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Row-wise Operations with `axis=1`**\n",
    "\n",
    "Apply logic that involves **multiple columns at once** (row-level logic):\n",
    "\n",
    "```python\n",
    "df[\"summary\"] = df.apply(\n",
    "    lambda row: f\"age: {row['age']} | job: {row['job']}\",\n",
    "    axis=1\n",
    ")\n",
    "```\n",
    "\n",
    "* `axis=1` → Apply function **row-wise**\n",
    "* `row['col_name']` → Access column values from the row (Series)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. Applying a Full Function Row-wise**\n",
    "\n",
    "```python\n",
    "def row_processor(row):\n",
    "    return f\"{row['age']} - {row['job']}\"\n",
    "\n",
    "df[\"summary\"] = df.apply(row_processor, axis=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **7. Dropping Columns**\n",
    "\n",
    "#### 🔹 Drop a single column:\n",
    "\n",
    "```python\n",
    "df = df.drop(\"summary\", axis=1)\n",
    "```\n",
    "\n",
    "#### 🔹 Drop multiple columns:\n",
    "\n",
    "```python\n",
    "df = df.drop([\"age\", \"job\"], axis=1)\n",
    "```\n",
    "\n",
    "> **Note**: Use `axis=1` to drop columns.\n",
    "> If not assigned back to `df`, changes are not permanent.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **8. Resetting Index and Dropping the Current Index Column**\n",
    "\n",
    "If the index was previously set to a column (e.g. `\"name\"`):\n",
    "\n",
    "```python\n",
    "df = df.reset_index()       # Moves index back to a column\n",
    "df = df.drop(\"name\", axis=1)  # Removes 'name' column\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Summary of Key Functions and Concepts\n",
    "\n",
    "| Concept                      | Method / Syntax                                          |\n",
    "| ---------------------------- | -------------------------------------------------------- |\n",
    "| Arithmetic on a column       | `df[\"col\"] * 2`, `df[\"col\"] / 2`                         |\n",
    "| Apply logic to a column      | `df[\"col\"].apply(func)`                                  |\n",
    "| Lambda for quick apply       | `df[\"col\"].apply(lambda x: x + 1)`                       |\n",
    "| Conditional transformation   | Define function with `if` logic and apply                |\n",
    "| Apply across rows            | `df.apply(func, axis=1)`                                 |\n",
    "| Create new columns from rows | Assign result of `apply(row_func, axis=1)` to new column |\n",
    "| Drop column                  | `df.drop(\"col\", axis=1)`                                 |\n",
    "| Drop multiple columns        | `df.drop([\"col1\", \"col2\"], axis=1)`                      |\n",
    "| Reset index                  | `df.reset_index()`                                       |\n",
    "| Set column as index          | `df.set_index(\"col\")`                                    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4dbeb7",
   "metadata": {},
   "source": [
    "### ✅ **Detecting Missing/Invalid Values** : Data Cleaning (42:44)\n",
    "\n",
    "* You can introduce a missing value (`NaN`) manually:\n",
    "\n",
    "  ```python\n",
    "  import numpy as np\n",
    "  df.at['Alice', 'age'] = float('nan')  # or np.nan\n",
    "  ```\n",
    "* Check missing info using:\n",
    "\n",
    "  ```python\n",
    "  df.info()  # Shows non-null count per column\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧹 **Handling Missing Values**\n",
    "\n",
    "#### 1. **Drop rows with any NaN**\n",
    "\n",
    "```python\n",
    "df.dropna()\n",
    "```\n",
    "\n",
    "* Removes any row that contains at least one NaN.\n",
    "* Example: If `Alice` has `NaN` in `age`, her row is removed.\n",
    "\n",
    "#### 2. **Fill NaN values**\n",
    "\n",
    "* Replace `NaN` with a specified value:\n",
    "\n",
    "  ```python\n",
    "  df.fillna(0)              # Replace NaN with 0\n",
    "  df.fillna(-1)             # Replace NaN with -1 (indicating \"invalid\")\n",
    "  df.fillna(df['age'].mean())  # Replace NaN with mean of `age` column\n",
    "  ```\n",
    "\n",
    "#### 3. **Drop rows based on specific columns only**\n",
    "\n",
    "* Remove rows where a particular column is `NaN`, not all columns:\n",
    "\n",
    "  ```python\n",
    "  df.dropna(subset=['age'])\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **Detecting NaNs using Boolean Masks**\n",
    "\n",
    "* Check which values are `NaN` or not:\n",
    "\n",
    "  ```python\n",
    "  df['age'].isna()        # True where value is NaN\n",
    "  df['age'].notna()       # True where value is NOT NaN\n",
    "  ```\n",
    "\n",
    "* Filter rows based on presence of values:\n",
    "\n",
    "  ```python\n",
    "  df[df['age'].notna()]   # Keep rows where 'age' is not NaN\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 **Additional Tips**\n",
    "\n",
    "* You can set `None` as missing value for non-numeric columns:\n",
    "\n",
    "  ```python\n",
    "  df.at['Bob', 'job'] = None\n",
    "  ```\n",
    "\n",
    "  This will count as missing (NaN in object column).\n",
    "\n",
    "* Use `.isna()` and `.notna()` to create Boolean masks for advanced filtering.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Operation                          | Function                      | Purpose                               |\n",
    "| ---------------------------------- | ----------------------------- | ------------------------------------- |\n",
    "| Detect missing values              | `df.isna()`                   | Returns Boolean DataFrame             |\n",
    "| Detect non-missing                 | `df.notna()`                  | Useful for filtering                  |\n",
    "| Drop rows with any NaN             | `df.dropna()`                 | Remove rows with at least 1 NaN       |\n",
    "| Drop rows based on specific column | `df.dropna(subset=['col'])`   | Remove rows where specific col is NaN |\n",
    "| Fill missing values                | `df.fillna(value)`            | Replace NaN with specified value      |\n",
    "| Mean imputation                    | `df.fillna(df['col'].mean())` | Use average of column to fill         |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6634805",
   "metadata": {},
   "source": [
    "### Iterating Over Data Frames (46:19)\n",
    "---\n",
    "### ✅ **1. Iterating Over Rows — `df.iterrows()`**\n",
    "\n",
    "* **Syntax:**\n",
    "\n",
    "  ```python\n",
    "  for index, row in df.iterrows():\n",
    "      # index: the row index (label)\n",
    "      # row: the row as a Series\n",
    "  ```\n",
    "\n",
    "* **What it returns:**\n",
    "  A **generator** that yields pairs of `(index, Series)`, where:\n",
    "\n",
    "  * `index` → Row label (e.g., 'Mike', 'Alice')\n",
    "  * `row` → Row data as a Pandas Series\n",
    "\n",
    "* **Example:**\n",
    "\n",
    "  ```python\n",
    "  for index, row in df.iterrows():\n",
    "      print(index)         # row label\n",
    "      print(row['summary']) # access column data by name\n",
    "  ```\n",
    "\n",
    "* **Use Case:**\n",
    "  Use when you want to process or inspect each **row individually** and access specific **column values** in each row.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Iterating Over Columns — `df.items()`**\n",
    "\n",
    "* **Syntax:**\n",
    "\n",
    "  ```python\n",
    "  for column_name, column_data in df.items():\n",
    "      # column_name: name of the column\n",
    "      # column_data: column as a Series\n",
    "  ```\n",
    "\n",
    "* **What it returns:**\n",
    "  A **generator** that yields pairs of `(column_name, Series)`, where:\n",
    "\n",
    "  * `column_name` → e.g., 'Age', 'Job', 'Summary'\n",
    "  * `column_data` → All values in that column (as Series)\n",
    "\n",
    "* **Example:**\n",
    "\n",
    "  ```python\n",
    "  for col, data in df.items():\n",
    "      print(col)       # column name\n",
    "      print(data)      # full column values (for all rows)\n",
    "  ```\n",
    "\n",
    "* **Use Case:**\n",
    "  Use when you want to process or inspect each **column individually** and access all its values.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 **Important Notes:**\n",
    "\n",
    "* `df.iterrows()` returns rows as Series → **slower**, not optimal for performance-critical code.\n",
    "* `df.items()` is efficient for **column-wise** iteration.\n",
    "* Avoid using `iterrows()` for large DataFrames when performance is important — prefer `vectorized` operations or `apply()`.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Summary Table\n",
    "\n",
    "| Method          | Iteration Target | Returns                | Access Style         |\n",
    "| --------------- | ---------------- | ---------------------- | -------------------- |\n",
    "| `df.iterrows()` | Rows             | (index, Series)        | `row['column_name']` |\n",
    "| `df.items()`    | Columns          | (column\\_name, Series) | `data[index]`        |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e53d0",
   "metadata": {},
   "source": [
    "### 🔍 **Filtering & Querying DataFrames in Pandas** : Filtering & Querying Data (48:03)\n",
    "\n",
    "Filtering in Pandas means selecting rows based on specific conditions. This is done using **Boolean masks** and can also be done with the `.query()` method.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Boolean Masking Basics**\n",
    "\n",
    "* **Comparison operators return a Boolean Series:**\n",
    "\n",
    "  ```python\n",
    "  df['age'] > 50\n",
    "  ```\n",
    "\n",
    "  Returns:\n",
    "\n",
    "  ```\n",
    "  False  # Mike (30)\n",
    "  False  # Alice (NaN)\n",
    "  True   # Bob (80)\n",
    "  True   # John (90)\n",
    "  ```\n",
    "\n",
    "* **Use Boolean Series to filter rows:**\n",
    "\n",
    "  ```python\n",
    "  df[df['age'] > 50]  # Only rows where age > 50\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Combining Conditions**\n",
    "\n",
    "* Use **`&` (AND)**, **`|` (OR)**, and **`~` (NOT)** with **parentheses**:\n",
    "\n",
    "  ```python\n",
    "  df[(df['age'] > 50) & (df['job'].notna())]\n",
    "  ```\n",
    "\n",
    "* **Negation** example:\n",
    "\n",
    "  ```python\n",
    "  df[~df['job'].notna()]  # Rows where job is None\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. String Filtering**\n",
    "\n",
    "* After turning the index into a column (if needed):\n",
    "\n",
    "  ```python\n",
    "  df = df.reset_index()\n",
    "  ```\n",
    "\n",
    "* Filter based on string conditions using `.str`:\n",
    "\n",
    "  ```python\n",
    "  df[df['name'].str.endswith('e')]  # e.g., names ending in 'e'\n",
    "  df[df['name'].str.contains('ic')] # names containing 'ic'\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Date Filtering**\n",
    "\n",
    "* Create a date column from age:\n",
    "\n",
    "  ```python\n",
    "  from datetime import datetime, timedelta\n",
    "  df['dob'] = df['age'].apply(lambda x: datetime.now() - timedelta(days=365 * x))\n",
    "  ```\n",
    "\n",
    "* Example: Filter by year of birth\n",
    "\n",
    "  ```python\n",
    "  df[df['dob'].dt.year > 1950]\n",
    "  ```\n",
    "\n",
    "* ⚠️ Must fill NaNs first to avoid errors:\n",
    "\n",
    "  ```python\n",
    "  df['age'] = df['age'].fillna(30)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Filtering with Lists (`.isin()`)**\n",
    "\n",
    "* Check if values are in a list:\n",
    "\n",
    "  ```python\n",
    "  accepted_ages = [30, 80]\n",
    "  df[df['age'].isin(accepted_ages)]\n",
    "  ```\n",
    "\n",
    "* Also works with strings, categories, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. Using `.query()` for Filtering**\n",
    "\n",
    "* Alternative filtering method using strings:\n",
    "\n",
    "  ```python\n",
    "  df.query(\"age > 30\")\n",
    "  df.query(\"age > 50 and job == 'Manager'\")\n",
    "  ```\n",
    "\n",
    "* **Advantages:**\n",
    "\n",
    "  * More **readable**\n",
    "  * Slightly **faster** on large DataFrames (uses **numexpr** backend)\n",
    "\n",
    "* **Limitations:**\n",
    "\n",
    "  * Doesn't support every Python or pandas expression (e.g., `.str` methods)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Summary Table of Filtering Methods**\n",
    "\n",
    "| Operation                | Syntax Example                           | Description                      |                              |\n",
    "| ------------------------ | ---------------------------------------- | -------------------------------- | ---------------------------- |\n",
    "| Filter by condition      | `df[df['age'] > 50]`                     | Basic filtering                  |                              |\n",
    "| Combine conditions (AND) | `df[(cond1) & (cond2)]`                  | Both conditions must be true     |                              |\n",
    "| Combine conditions (OR)  | \\`df\\[(cond1)                            | (cond2)]\\`                       | Either condition can be true |\n",
    "| Negate condition         | `df[~df['job'].notna()]`                 | Inverse of the condition         |                              |\n",
    "| String match             | `df[df['name'].str.endswith('e')]`       | Works on string columns          |                              |\n",
    "| Value in list            | `df[df['age'].isin([30, 80])]`           | Matches multiple specific values |                              |\n",
    "| Query syntax             | `df.query(\"age > 30 and job != 'None'\")` | String-based filtering           |                              |\n",
    "| Date filtering           | `df[df['dob'].dt.year > 1950]`           | Filter based on date components  |                              |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819046b",
   "metadata": {},
   "source": [
    "### 🔗 **Pandas Grouping and Aggregation (GroupBy)** : Grouping Data (55:01)\n",
    "\n",
    "Grouping is useful when you want to calculate **aggregated statistics** for subsets of your data that share a common feature (e.g., same job type).\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Grouping Data**\n",
    "\n",
    "* Group the DataFrame by a column:\n",
    "\n",
    "  ```python\n",
    "  df.groupby('job')\n",
    "  ```\n",
    "\n",
    "  This returns a **GroupBy object** (not a DataFrame yet).\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **2. Aggregating with `.agg()`**\n",
    "\n",
    "* Convert the GroupBy object into a DataFrame by applying an aggregation function:\n",
    "\n",
    "  ```python\n",
    "  df.groupby('job').agg({'age': 'mean'})\n",
    "  ```\n",
    "\n",
    "  * Groups the rows by `job`\n",
    "  * Calculates the **mean age** per group\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **3. Multiple Aggregations**\n",
    "\n",
    "* You can apply **multiple aggregation functions**:\n",
    "\n",
    "  ```python\n",
    "  df.groupby('job').agg({\n",
    "      'age': ['mean', 'min', 'max', 'sum']\n",
    "  })\n",
    "  ```\n",
    "\n",
    "  This produces a multi-level column DataFrame with all specified metrics:\n",
    "\n",
    "  * **mean** – average age per group\n",
    "  * **min** – youngest in group\n",
    "  * **max** – oldest in group\n",
    "  * **sum** – total of ages\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **4. Updating Values for Grouping**\n",
    "\n",
    "* You can **modify the data** before grouping:\n",
    "\n",
    "  ```python\n",
    "  df['job'] = df['job'].fillna('programmer')  # Fill missing jobs\n",
    "  df = df.drop(columns='summary')            # Drop unnecessary column\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **5. Adding Rows**\n",
    "\n",
    "* Add a new row with `.loc`:\n",
    "\n",
    "  ```python\n",
    "  df.loc[4] = ['Jane', 35, 'programmer', pd.NaT]\n",
    "  ```\n",
    "\n",
    "  Adds \"Jane\" as a programmer with age 35 and no birthday (`NaT` = Not a Time)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **6. Practical Example**\n",
    "\n",
    "If you have Bob (80y) and Jane (35y) as programmers:\n",
    "\n",
    "```python\n",
    "df.groupby('job').agg({'age': 'mean'})\n",
    "```\n",
    "\n",
    "Returns:\n",
    "\n",
    "```\n",
    "job         age\n",
    "programmer  57.5   # (80 + 35) / 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **7. Advanced Aggregations**\n",
    "\n",
    "* You can use `.apply()` for custom functions on groups (beyond the scope of basic usage):\n",
    "\n",
    "  ```python\n",
    "  df.groupby('job').apply(custom_function)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Summary Table: GroupBy & Aggregation**\n",
    "\n",
    "| Operation                          | Example Code                                             | Description                        |\n",
    "| ---------------------------------- | -------------------------------------------------------- | ---------------------------------- |\n",
    "| Basic grouping                     | `df.groupby('job')`                                      | Returns GroupBy object             |\n",
    "| Single aggregation                 | `df.groupby('job').agg({'age': 'mean'})`                 | Mean age per job group             |\n",
    "| Multiple aggregations              | `df.groupby('job').agg({'age': ['mean', 'min', 'max']})` | Aggregates several stats per group |\n",
    "| Fill missing job values            | `df['job'] = df['job'].fillna('programmer')`             | Ensures consistent grouping        |\n",
    "| Drop column                        | `df = df.drop(columns='summary')`                        | Clean up irrelevant data           |\n",
    "| Add a row                          | `df.loc[4] = ['Jane', 35, 'programmer', pd.NaT]`         | Manual data entry                  |\n",
    "| Custom group operations (advanced) | `df.groupby('job').apply(func)`                          | Apply custom logic to each group   |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e566350",
   "metadata": {},
   "source": [
    "### Sorting and Merging\n",
    "---\n",
    "\n",
    "## 🔽 **Sorting Data in Pandas**\n",
    "\n",
    "### ✅ `sort_values()`\n",
    "\n",
    "* Sort DataFrame **by column values**, not index:\n",
    "\n",
    "  ```python\n",
    "  df.sort_values('age')  # Ascending by default\n",
    "  df.sort_values('age', ascending=False)  # Descending\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 **Concatenating, Merging, and Joining DataFrames**\n",
    "\n",
    "---\n",
    "\n",
    "### 📚 **1. Concatenation (`pd.concat`)**\n",
    "\n",
    "#### ➕ **Stacking Rows (Vertical Concatenation)**\n",
    "\n",
    "* Combine rows of multiple DataFrames:\n",
    "\n",
    "  ```python\n",
    "  pd.concat([df1, df2])\n",
    "  ```\n",
    "* Reset the index after concatenation:\n",
    "\n",
    "  ```python\n",
    "  pd.concat([df1, df2]).reset_index(drop=True)\n",
    "  ```\n",
    "\n",
    "#### ➕ **Stacking Columns (Horizontal Concatenation)**\n",
    "\n",
    "* Combine columns **side-by-side** (requires matching indices):\n",
    "\n",
    "  ```python\n",
    "  pd.concat([df1, df2], axis=1)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 **2. Merging (`pd.merge`)**\n",
    "\n",
    "#### 🔁 **Basic Inner Merge**\n",
    "\n",
    "* Merge two DataFrames **on common columns** (default is `how='inner'`):\n",
    "\n",
    "  ```python\n",
    "  pd.merge(df1, df2)\n",
    "  ```\n",
    "\n",
    "#### 📌 **Specify Merge Column**\n",
    "\n",
    "* Explicitly merge **on a specific column**:\n",
    "\n",
    "  ```python\n",
    "  pd.merge(df1, df2, on='item')\n",
    "  ```\n",
    "\n",
    "#### 🔧 **Merge Types (`how=` parameter)**\n",
    "\n",
    "| Type      | Description                                            |\n",
    "| --------- | ------------------------------------------------------ |\n",
    "| `'inner'` | Default. Only keeps matching rows in both              |\n",
    "| `'outer'` | Keeps **all** rows from both; fills missing with `NaN` |\n",
    "| `'left'`  | All rows from **left df**, matched rows from right     |\n",
    "| `'right'` | All rows from **right df**, matched rows from left     |\n",
    "\n",
    "#### 🧩 **Example:**\n",
    "\n",
    "```python\n",
    "pd.merge(df1, df2, on='item', how='outer')\n",
    "```\n",
    "\n",
    "* Merges on `'item'`\n",
    "* Keeps all rows from both DataFrames\n",
    "* Missing values filled with `NaN`\n",
    "\n",
    "---\n",
    "\n",
    "### 🧷 **3. Joining (on index) with `.join()`**\n",
    "\n",
    "#### 🔗 **Index-Based Join**\n",
    "\n",
    "* Used to **join two DataFrames based on index**:\n",
    "\n",
    "  ```python\n",
    "  df1.join(df2)  # Equivalent to df1.join(df2, how='left')\n",
    "  ```\n",
    "\n",
    "#### 🔧 **Join Types (same as `merge`)**\n",
    "\n",
    "* Options: `how='left'`, `how='right'`, `how='inner'`, `how='outer'`\n",
    "\n",
    "#### 🧩 **Example:**\n",
    "\n",
    "```python\n",
    "df1.join(df2, how='outer')  # All indices from both df1 and df2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Summary Table\n",
    "\n",
    "| Task                            | Method                          | Key Notes                                        |\n",
    "| ------------------------------- | ------------------------------- | ------------------------------------------------ |\n",
    "| Sort by column                  | `df.sort_values('col')`         | Add `ascending=False` for descending             |\n",
    "| Concatenate rows                | `pd.concat([df1, df2])`         | Use `reset_index(drop=True)` to clean index      |\n",
    "| Concatenate columns             | `pd.concat([df1, df2], axis=1)` | Indices must match                               |\n",
    "| Merge on column (inner)         | `pd.merge(df1, df2)`            | Common values only                               |\n",
    "| Merge on column (outer/left...) | `pd.merge(df1, df2, how='...')` | Outer: all rows, Left: df1 base, Right: df2 base |\n",
    "| Merge on specific column        | `pd.merge(df1, df2, on='item')` | Define merge key                                 |\n",
    "| Join on index                   | `df1.join(df2)`                 | Works only when joining by index                 |\n",
    "| Join with options               | `df1.join(df2, how='outer')`    | Supports same join types as merge                |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
